import requests
from bs4 import BeautifulSoup
from openpyxl import Workbook

def crawl_douban_top250():
    """çˆ¬å–è±†ç“£ç”µå½±TOP250"""
    wb = Workbook()
    ws = wb.active
    ws.append(["æ’å", "ç”µå½±å", "è¯„åˆ†", "å¯¼æ¼”/ä¸»æ¼”", "ç®€ä»‹"])
    base_url = "https://movie.douban.com/top250"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    for page in range(10):  # å…±10é¡µï¼Œæ¯é¡µ25æ¡
        url = base_url + f"?start={page*25}"
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")
        movies = soup.find_all("div", class_="item")
        for movie in movies:
            rank = movie.find("em", class_="").text
            name = movie.find("span", class_="title").text
            score = movie.find("span", class_="rating_num").text
            info = movie.find("p", class_="").text.strip()
            intro = movie.find("span", class_="inq").text if movie.find("span", class_="inq") else "æ— ç®€ä»‹"
            ws.append([rank, name, score, info, intro])
            print(f"âœ… çˆ¬å–æˆåŠŸï¼š{rank}. {name} - {score}åˆ†")
    wb.save("è±†ç“£ç”µå½±TOP250.xlsx")
    print("ğŸ‰ å…¨éƒ¨çˆ¬å–å®Œæˆï¼å·²ä¿å­˜ä¸ºExcelæ–‡ä»¶")

if __name__ == "__main__":
    crawl_douban_top250()